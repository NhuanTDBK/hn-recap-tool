# Story 7.4: Application Deployment & Service Management

---

## Status

**Draft**

---

## Story

**As a** DevOps engineer,
**I want** the HackerNews Digest application fully containerized and running on EC2 via Docker Compose with a simple rolling update strategy,
**so that** the Telegram bot is live in production, all services are managed consistently, and updates can be deployed with zero message loss.

---

## Acceptance Criteria

1. `docker-compose.prod.yml` defines 3 services: `app`, `postgres`, `redis` — all in one Compose file
2. `Dockerfile` in `backend/` builds the app image (Python 3.11, uv, application code, RocksDB)
3. PostgreSQL 15 container memory-tuned for t3.micro (`shared_buffers=64MB`, `work_mem=4MB`, memory limit 256M)
4. Redis 7 container with memory limit (64M)
5. Application code deployed to EC2 via `git clone` to `/opt/hnpal/`
6. Alembic migrations run via `docker compose exec app` or as part of app container startup
7. Secrets managed: Terraform sensitive variables → `.env` on EC2 (mode 600) → Docker Compose `env_file`
8. All services start with `docker compose up -d` and auto-restart via `restart: unless-stopped`
9. Telegram bot responds to `/start` command (polling mode)
10. Rolling update works: `git pull && docker compose up -d --build --no-deps app` — only app restarts, PostgreSQL + Redis untouched, Telegram buffers messages during ~3-5s gap
11. `infra/README.md` documents: prerequisites (AWS account, AWS CLI, Terraform, SSH key pair), quick start, variable reference, SSH access, deploy/update commands, cost estimates

---

## Tasks / Subtasks

- [ ] **Task 1: Create production Dockerfile** (AC: 2)
  - [ ] Create `backend/Dockerfile`:
    ```dockerfile
    FROM python:3.11-slim

    # System dependencies for RocksDB
    RUN apt-get update && apt-get install -y \
        build-essential \
        librocksdb-dev \
        libgflags-dev \
        libsnappy-dev \
        zlib1g-dev \
        libbz2-dev \
        liblz4-dev \
        libzstd-dev \
        && rm -rf /var/lib/apt/lists/*

    # Install uv
    COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

    WORKDIR /app

    # Install dependencies first (cache layer)
    COPY pyproject.toml uv.lock ./
    RUN uv sync --frozen --no-dev

    # Copy application code
    COPY . .

    CMD ["uv", "run", "python", "-m", "app.main"]
    ```
  - [ ] Add `.dockerignore` in `backend/`:
    ```
    __pycache__
    *.pyc
    .venv
    .env
    tests/
    .pytest_cache
    .mypy_cache
    .ruff_cache
    ```

- [ ] **Task 2: Create production Docker Compose** (AC: 1, 3, 4, 8)
  - [ ] Create `docker-compose.prod.yml` at project root:
    ```yaml
    services:
      app:
        build: ./backend
        container_name: hnpal-app
        env_file: .env
        depends_on:
          postgres:
            condition: service_healthy
          redis:
            condition: service_healthy
        restart: unless-stopped
        volumes:
          - rocksdb_data:/app/data
        deploy:
          resources:
            limits:
              memory: 512M

      postgres:
        image: postgres:15-alpine
        container_name: hnpal-postgres
        env_file: .env
        restart: unless-stopped
        command: >
          postgres
          -c shared_buffers=64MB
          -c work_mem=4MB
          -c maintenance_work_mem=32MB
          -c effective_cache_size=128MB
        volumes:
          - postgres_data:/var/lib/postgresql/data
        healthcheck:
          test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-hn_pal}"]
          interval: 10s
          timeout: 5s
          retries: 5
        deploy:
          resources:
            limits:
              memory: 256M

      redis:
        image: redis:7-alpine
        container_name: hnpal-redis
        restart: unless-stopped
        command: redis-server --maxmemory 48mb --maxmemory-policy allkeys-lru
        volumes:
          - redis_data:/data
        healthcheck:
          test: ["CMD", "redis-cli", "ping"]
          interval: 10s
          timeout: 5s
          retries: 5
        deploy:
          resources:
            limits:
              memory: 64M

    volumes:
      rocksdb_data:
      postgres_data:
      redis_data:
    ```

- [ ] **Task 3: Configure secrets management** (AC: 7)
  - [ ] Add sensitive Terraform variables to `infra/variables.tf`:
    - `telegram_bot_token` (string, sensitive, required)
    - `openai_api_key` (string, sensitive, required)
    - `database_password` (string, sensitive, default `"hnpal_prod_2026"`)
    - `langfuse_public_key` (string, sensitive, default `""`)
    - `langfuse_secret_key` (string, sensitive, default `""`)
    - `app_git_repo` (string, default `"https://github.com/<user>/hackernews_digest.git"`)
  - [ ] Update `infra/terraform.tfvars.example`:
    ```hcl
    aws_region         = "ap-southeast-1"
    key_pair_name      = "my-key-pair"
    telegram_bot_token = "123456789:ABC..."
    openai_api_key     = "sk-proj-..."
    database_password  = "change-me-strong-password"
    app_git_repo       = "https://github.com/user/hackernews_digest.git"
    ```
  - [ ] Update `templatefile()` in `ec2.tf` to pass all secrets to user-data

- [ ] **Task 4: Update user-data.sh for full deployment** (AC: 5, 6, 7, 8)
  - [ ] Extend `infra/scripts/user-data.sh` to add after existing bootstrap:
    ```bash
    # Write .env file with secrets
    cat > /opt/hnpal/.env << 'ENVEOF'
    # Database
    DATABASE_URL=postgresql+asyncpg://hn_pal:${DB_PASSWORD}@postgres:5432/hn_pal
    POSTGRES_USER=hn_pal
    POSTGRES_PASSWORD=${DB_PASSWORD}
    POSTGRES_DB=hn_pal
    REDIS_URL=redis://redis:6379/0

    # Telegram
    TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}

    # OpenAI
    OPENAI_API_KEY=${OPENAI_API_KEY}

    # Observability (optional)
    LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
    LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}

    # Application
    ENVIRONMENT=production
    LOG_LEVEL=INFO
    ENVEOF
    chmod 600 /opt/hnpal/.env
    chown ubuntu:ubuntu /opt/hnpal/.env

    # Clone application
    sudo -u ubuntu git clone ${APP_GIT_REPO} /opt/hnpal/app || \
      (cd /opt/hnpal/app && sudo -u ubuntu git pull)

    # Copy production compose file
    cp /opt/hnpal/app/docker-compose.prod.yml /opt/hnpal/docker-compose.yml

    # Start all services
    cd /opt/hnpal
    docker compose up -d --build

    # Wait for healthy services
    echo "Waiting for services to be healthy..."
    sleep 15

    # Run database migrations
    docker compose exec -T app uv run alembic upgrade head

    echo "=== Application deployment complete $(date) ==="
    ```
  - [ ] Update `templatefile()` to pass: `DB_PASSWORD`, `TELEGRAM_BOT_TOKEN`, `OPENAI_API_KEY`, `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `APP_GIT_REPO`

- [ ] **Task 5: Create deploy/update script** (AC: 10)
  - [ ] Create `infra/scripts/deploy-update.sh`:
    ```bash
    #!/bin/bash
    # Run on EC2 to update the application (zero message loss)
    set -euo pipefail

    cd /opt/hnpal/app
    echo "Pulling latest code..."
    git pull

    echo "Rebuilding and restarting app container only..."
    cd /opt/hnpal
    docker compose up -d --build --no-deps app

    echo "Running migrations..."
    docker compose exec -T app uv run alembic upgrade head

    echo "Checking health..."
    sleep 5
    docker compose ps

    echo "Update complete! Telegram buffered any messages during ~3-5s restart."
    ```

- [ ] **Task 6: Create infrastructure documentation** (AC: 11)
  - [ ] Create `infra/README.md` with sections:
    - **Prerequisites:**
      - AWS account with billing enabled
      - AWS CLI installed + `aws configure` with IAM user credentials
      - Terraform >= 1.5 installed
      - SSH Key Pair created in AWS Console (EC2 → Key Pairs)
    - **Quick Start:**
      1. `cd infra`
      2. `cp terraform.tfvars.example terraform.tfvars`
      3. Edit `terraform.tfvars` with real values
      4. `terraform init`
      5. `terraform plan`
      6. `terraform apply` (wait ~5 min for full deployment)
      7. `terraform output ssh_command` — copy and SSH in
    - **Variable Reference:** table of all variables
    - **Architecture Diagram:** from epic doc
    - **SSH Access:** `terraform output ssh_command`
    - **Check Status:**
      - `docker compose ps` — all 3 services running
      - `docker compose logs -f app` — app logs
      - `docker compose logs postgres` — DB logs
    - **Update Application:**
      - `ssh into EC2`
      - `bash /opt/hnpal/app/infra/scripts/deploy-update.sh`
    - **Destroy:** `terraform destroy`
    - **Cost:** free tier table + post-free-tier estimate

- [ ] **Task 7: End-to-end verification** (AC: 9, 10)
  - [ ] Run `terraform apply` with all variables (including secrets in `terraform.tfvars`)
  - [ ] Wait ~5 min for user-data to complete
  - [ ] SSH in and verify:
    - `docker compose ps` — 3 services: app, postgres, redis (all "Up (healthy)")
    - `docker compose logs app --tail 20` — no errors, bot started
    - `df -h /mnt/s3data` — S3 mounted
    - `ls /opt/hnpal/.env` — exists, mode 600
  - [ ] Send `/start` to Telegram bot — verify response
  - [ ] Test rolling update:
    - Run `deploy-update.sh`
    - Verify app restarts, postgres/redis untouched
    - Verify bot still responds after update
  - [ ] Test reboot:
    - `sudo reboot`
    - Wait 2 min, SSH back in
    - `docker compose ps` — all services back up
    - S3 mount still active
  - [ ] `terraform destroy` — clean removal

---

## Dev Notes

### Memory Budget (t3.micro = 1024 MB)

| Component | Memory Limit | Notes |
|-----------|-------------|-------|
| OS + kernel | ~100 MB | Fixed |
| Docker daemon | ~70 MB | Fixed |
| app container | 512 MB limit | Bot + scheduler + RocksDB |
| postgres container | 256 MB limit | Tuned: shared_buffers=64MB |
| redis container | 64 MB limit | maxmemory=48mb + overhead |
| **Total limits** | **~1002 MB** | Tight but workable |

If OOM issues occur: reduce app limit to 384M or upgrade to t3.small (2 GB, ~$15/mo).

### Application Entry Point

Verify the correct entry point from the codebase:

```bash
# Likely candidates:
uv run python -m app.main           # If main.py exists with bot + scheduler
uv run python scripts/run_bot.py    # If separate bot script
uv run python scripts/run_full_flow.py  # If unified runner
```

[Source: docs/architecture/source-tree.md — scripts/ directory]

Check `backend/app/main.py` and update the Dockerfile `CMD` accordingly.

### Docker Networking

All containers share a Docker Compose network. Database URLs use **container names** as hostnames:
- `postgresql+asyncpg://hn_pal:pass@postgres:5432/hn_pal` (not `localhost`)
- `redis://redis:6379/0` (not `localhost`)

This is different from local dev where services are on `localhost`.

### RocksDB in Docker

RocksDB data persisted via Docker named volume `rocksdb_data`. This maps to the local EBS disk (not S3). The volume survives container restarts and rebuilds.

### Rolling Update — How It Works

```
Before:  app:v1 ── postgres ── redis     (bot polling Telegram)
         │
Step 1:  app:v1 stops                    (Telegram buffers messages)
         ~3-5 seconds
Step 2:  app:v2 starts                   (bot reconnects, processes buffered messages)
         │
After:   app:v2 ── postgres ── redis     (bot polling Telegram)
```

- PostgreSQL and Redis are **never restarted** during app updates
- Telegram queues undelivered updates for up to **24 hours**
- Users experience 0 message loss, at most ~5 second delay

### Secrets Flow

```
Developer's machine                      EC2 Instance
─────────────────                        ────────────
terraform.tfvars (gitignored)
  ↓ terraform apply
EC2 user-data (base64 in metadata)
  ↓ bootstrap script writes
/opt/hnpal/.env (mode 600, owner ubuntu)
  ↓ docker compose env_file
Container environment variables
  ↓ pydantic Settings reads
Python os.environ
```

### S3 Mount Usage

| Path | Purpose |
|------|---------|
| `/mnt/s3data/backups/` | PostgreSQL pg_dump backups |
| `/mnt/s3data/logs/` | Archived application logs |
| `/mnt/s3data/exports/` | Data exports |

RocksDB stays on local EBS (Docker volume) for write performance.

### File Structure After This Story

```
infra/
├── main.tf
├── s3.tf
├── iam.tf
├── ec2.tf
├── variables.tf             # + all secret variables
├── outputs.tf
├── terraform.tfvars.example # + all variable examples
├── scripts/
│   ├── user-data.sh         # Full bootstrap + app deployment
│   └── deploy-update.sh     # Rolling update script
└── README.md                # Complete documentation

backend/
├── Dockerfile               # Production app image
├── .dockerignore
└── ...

docker-compose.prod.yml      # Production compose (app + postgres + redis)
```

### Testing

**Full end-to-end manual test:**
1. `terraform apply` → wait 5 min
2. SSH → `docker compose ps` → 3 healthy services
3. Send `/start` to bot → responds
4. Run `deploy-update.sh` → app restarts, bot still works
5. `sudo reboot` → services auto-restart
6. `terraform destroy` → clean

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-02-23 | 1.0 | Initial story creation (Epic 7 breakdown) | BMad Master |
| 2026-02-23 | 2.0 | Fully Dockerized app, simple rolling update, t3.micro tuning | BMad Master |

---

## Dev Agent Record

### Agent Model Used

_To be filled during implementation_

### Debug Log References

_To be filled during implementation_

### Completion Notes List

_To be filled during implementation_

### File List

_To be filled during implementation_

---

## QA Results

_To be filled by QA Agent_
